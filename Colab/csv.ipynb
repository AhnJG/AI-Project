{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "csv.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlDKftIftMiI0EKSig6YN+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhnJG/AI-Project/blob/master/Colab/csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C-3Xbt0FfGfs"
      },
      "source": [
        "This tutorial provides an example of how to load CSV data from a file into a `tf.data.Dataset`.\n",
        "\n",
        "The data used in this tutorial are taken from the Titanic passenger list. The model will predict the likelihood a passenger survived based on characteristics like age, gender, ticket class, and whether the person was traveling alone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fgZ9gjmPfSnK"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVqyyVsKuiXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9141241d-e7c9-4f6c-a20c-019714a45241"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H5WXJK8usUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkZKTITbu179",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eb128c63-feb6-4438-ec97-55997d7e8bcb"
      },
      "source": [
        "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
        "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
        "\n",
        "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
        "test_file_path = tf.keras.utils.get_file(\"test.csv\", TEST_DATA_URL)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
            "16384/13049 [=====================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF5LXdpdvFH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make numpy values easier to read\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wuqj601Qw0Ml"
      },
      "source": [
        "## Load data\n",
        "\n",
        "To start, let's look at the top of the CSV file to see how it is formatted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVNjcOIvvPlB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "274caf59-64e1-47bc-bf00-894d066dceb0"
      },
      "source": [
        "!head {train_file_path}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone\n",
            "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n",
            "1,female,38.0,1,0,71.2833,First,C,Cherbourg,n\n",
            "1,female,26.0,0,0,7.925,Third,unknown,Southampton,y\n",
            "1,female,35.0,1,0,53.1,First,C,Southampton,n\n",
            "0,male,28.0,0,0,8.4583,Third,unknown,Queenstown,y\n",
            "0,male,2.0,3,1,21.075,Third,unknown,Southampton,n\n",
            "1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n\n",
            "1,female,14.0,1,0,30.0708,Second,unknown,Cherbourg,n\n",
            "1,female,4.0,1,1,16.7,Third,G,Southampton,n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jC9lRhV-q_R3"
      },
      "source": [
        "You can [load this using pandas](pandas.ipynb), and pass the NumPy arrays to TensorFlow. If you need to scale up to a large set of files, or need a loader that integrates with [TensorFlow and tf.data](../../guide/data.ipynb) then use the `tf.data.experimental.make_csv_dataset` function:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "67mfwr4v-mN_"
      },
      "source": [
        "The only column you need to identify explicitly is the one with the value that the model is intended to predict. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wq9hTt_vVFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLUMN = 'survived'\n",
        "LABELS = [0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t4N-plO4tDXd"
      },
      "source": [
        "Now read the CSV data from the file and create a dataset. \n",
        "\n",
        "(For the full documentation, see `tf.data.experimental.make_csv_dataset`)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENXdxV3qvdpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset(file_path, **kwargs):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file_path,\n",
        "      batch_size=5, # Artificially small to make examples easier to show.\n",
        "      label_name=LABEL_COLUMN,\n",
        "      na_value=\"?\",\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True, \n",
        "      **kwargs)\n",
        "  return dataset\n",
        "\n",
        "raw_train_data = get_dataset(train_file_path)\n",
        "raw_test_data = get_dataset(test_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivv_IowWvg-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_batch(dataset):\n",
        "  for batch, label in dataset.take(1):\n",
        "    for key, value in batch.items():\n",
        "      print(\"{:20s}: {}\".format(key,value.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vHUQFKoQI6G7"
      },
      "source": [
        "Each item in the dataset is a batch, represented as a tuple of (*many examples*, *many labels*). The data from the examples is organized in column-based tensors (rather than row-based tensors), each with as many elements as the batch size (5 in this case).\n",
        "\n",
        "It might help to see this yourself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HjrkJROoxoll",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "85cd720e-3471-41bc-b2d9-98f5fdeeb14a"
      },
      "source": [
        "show_batch(raw_train_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'male' b'male' b'male' b'male' b'female']\n",
            "age                 : [55.5 28.  47.  28.  36. ]\n",
            "n_siblings_spouses  : [0 3 0 0 0]\n",
            "parch               : [0 1 0 0 2]\n",
            "fare                : [ 8.05  25.467 38.5   15.05  71.   ]\n",
            "class               : [b'Third' b'Third' b'First' b'Second' b'First']\n",
            "deck                : [b'unknown' b'unknown' b'E' b'unknown' b'B']\n",
            "embark_town         : [b'Southampton' b'Southampton' b'Southampton' b'Cherbourg' b'Southampton']\n",
            "alone               : [b'y' b'n' b'y' b'y' b'n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YOYKQKmMj3D6"
      },
      "source": [
        "As you can see, the columns in the CSV are named. The dataset constructor will pick these names up automatically. If the file you are working with does not contain the column names in the first line, pass them in a list of strings to  the `column_names` argument in the `make_csv_dataset` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Av8_9L3tUg1",
        "colab": {}
      },
      "source": [
        "CSV_COLUMNS = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
        "\n",
        "temp_dataset = get_dataset(train_file_path, column_names=CSV_COLUMNS)\n",
        "\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gZfhoX7bR9u4"
      },
      "source": [
        "This example is going to use all the available columns. If you need to omit some columns from the dataset, create a list of just the columns you plan to use, and pass it into the (optional) `select_columns` argument of the constructor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1TzSkUKwsNP",
        "colab": {}
      },
      "source": [
        "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'class', 'deck', 'alone']\n",
        "\n",
        "temp_dataset = get_dataset(train_file_path, select_columns=SELECT_COLUMNS)\n",
        "\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9cryz31lxs3e"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "A CSV file can contain a variety of data types. Typically you want to convert from those mixed types to a fixed length vector before feeding the data into your model.\n",
        "\n",
        "TensorFlow has a built-in system for describing common input conversions: `tf.feature_column`, see [this tutorial](../keras/feature_columns) for details.\n",
        "\n",
        "\n",
        "You can preprocess your data using any tool you like (like [nltk](https://www.nltk.org/) or [sklearn](https://scikit-learn.org/stable/)), and just pass the processed output to TensorFlow. \n",
        "\n",
        "\n",
        "The primary advantage of doing the preprocessing inside your model is that when you export the model it includes the preprocessing. This way you can pass the raw data directly to your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9AsbaFmCeJtF"
      },
      "source": [
        "### Continuous data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xl0Q0DcfA_rt"
      },
      "source": [
        "If your data is already in an appropriate numeric format, you can pack the data into a vector before passing it off to the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4Yfji3J5BMxz",
        "colab": {}
      },
      "source": [
        "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'parch', 'fare']\n",
        "DEFAULTS = [0, 0.0, 0.0, 0.0, 0.0]\n",
        "temp_dataset = get_dataset(train_file_path, \n",
        "                           select_columns=SELECT_COLUMNS,\n",
        "                           column_defaults = DEFAULTS)\n",
        "\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zEUhI8kZCfq8",
        "colab": {}
      },
      "source": [
        "example_batch, labels_batch = next(iter(temp_dataset)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IP45_2FbEKzn"
      },
      "source": [
        "Here's a simple function that will pack together all the columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JQ0hNSL8CC3a",
        "colab": {}
      },
      "source": [
        "def pack(features, label):\n",
        "  return tf.stack(list(features.values()), axis=-1), label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "75LA9DisEIoE"
      },
      "source": [
        "Apply this to each element of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VnP2Z2lwCTRl",
        "colab": {}
      },
      "source": [
        "packed_dataset = temp_dataset.map(pack)\n",
        "\n",
        "for features, labels in packed_dataset.take(1):\n",
        "  print(features.numpy())\n",
        "  print()\n",
        "  print(labels.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1VBvmaFrFU6J"
      },
      "source": [
        "If you have mixed datatypes you may want to separate out these simple-numeric fields. The `tf.feature_column` api can handle them, but this incurs some overhead and should be avoided unless really necessary. Switch back to the mixed dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ad-IQ_JPFQge",
        "colab": {}
      },
      "source": [
        "show_batch(raw_train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HSrYNKKcIdav",
        "colab": {}
      },
      "source": [
        "example_batch, labels_batch = next(iter(temp_dataset)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p5VtThKfGPaQ"
      },
      "source": [
        "So define a more general preprocessor that selects a list of numeric features and packs them into a single column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5DRishYYGS-m",
        "colab": {}
      },
      "source": [
        "class PackNumericFeatures(object):\n",
        "  def __init__(self, names):\n",
        "    self.names = names\n",
        "\n",
        "  def __call__(self, features, labels):\n",
        "    numeric_features = [features.pop(name) for name in self.names]\n",
        "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "    numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "    features['numeric'] = numeric_features\n",
        "\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1SeZka9AHfqD",
        "colab": {}
      },
      "source": [
        "NUMERIC_FEATURES = ['age','n_siblings_spouses','parch', 'fare']\n",
        "\n",
        "packed_train_data = raw_train_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))\n",
        "\n",
        "packed_test_data = raw_test_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wFrw0YobIbUB",
        "colab": {}
      },
      "source": [
        "show_batch(packed_train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_EPUS8fPLUb1",
        "colab": {}
      },
      "source": [
        "example_batch, labels_batch = next(iter(packed_train_data)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o2maE8d2ijsq"
      },
      "source": [
        "#### Data Normalization\n",
        "\n",
        "Continuous data should always be normalized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WKT1ASWpwH46",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "desc = pd.read_csv(train_file_path)[NUMERIC_FEATURES].describe()\n",
        "desc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cHHstcKPsMXM",
        "colab": {}
      },
      "source": [
        "MEAN = np.array(desc.T['mean'])\n",
        "STD = np.array(desc.T['std'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "REKqO_xHPNx0",
        "colab": {}
      },
      "source": [
        "def normalize_numeric_data(data, mean, std):\n",
        "  # Center the data\n",
        "  return (data-mean)/std\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VPsoMUgRCpUM"
      },
      "source": [
        "Now create a numeric column. The `tf.feature_columns.numeric_column` API accepts a `normalizer_fn` argument, which will be run on each batch.\n",
        "\n",
        "Bind the `MEAN` and `STD` to the normalizer fn using [`functools.partial`](https://docs.python.org/3/library/functools.html#functools.partial)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bw0I35xRS57V",
        "colab": {}
      },
      "source": [
        "# See what you just created.\n",
        "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
        "\n",
        "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
        "numeric_columns = [numeric_column]\n",
        "numeric_column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HZxcHXc6LCa7"
      },
      "source": [
        "When you train the model, include this feature column to select and center this block of numeric data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b61NM76Ot_kb",
        "colab": {}
      },
      "source": [
        "example_batch['numeric']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j-r_4EAJAZoI",
        "colab": {}
      },
      "source": [
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
        "numeric_layer(example_batch).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M37oD2VcCO4R"
      },
      "source": [
        "The mean based normalization used here requires knowing the means of each column ahead of time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tSyrkSQwYHKi"
      },
      "source": [
        "### Categorical data\n",
        "\n",
        "Some of the columns in the CSV data are categorical columns. That is, the content should be one of a limited set of options.\n",
        "\n",
        "Use the `tf.feature_column` API to create a collection with a `tf.feature_column.indicator_column` for each categorical column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mWDniduKMw-C",
        "colab": {}
      },
      "source": [
        "CATEGORIES = {\n",
        "    'sex': ['male', 'female'],\n",
        "    'class' : ['First', 'Second', 'Third'],\n",
        "    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
        "    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
        "    'alone' : ['y', 'n']\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kkxLdrsLwHPT",
        "colab": {}
      },
      "source": [
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H18CxpHY_Nma",
        "colab": {}
      },
      "source": [
        "# See what you just created.\n",
        "categorical_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p7mACuOsArUH",
        "colab": {}
      },
      "source": [
        "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
        "print(categorical_layer(example_batch).numpy()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R7-1QG99_1sN"
      },
      "source": [
        "This will be become part of a data processing input later when you build the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kPWkC4_1l3IG"
      },
      "source": [
        "### Combined preprocessing layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R3QAjo1qD4p9"
      },
      "source": [
        "Add the two feature column collections and pass them to a `tf.keras.layers.DenseFeatures` to create an input layer that will extract and preprocess both input types:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3-OYK7GnaH0r",
        "colab": {}
      },
      "source": [
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m7_U_K0UMSVS",
        "colab": {}
      },
      "source": [
        "print(preprocessing_layer(example_batch).numpy()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DlF_omQqtnOP"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lQoFh16LxtT_"
      },
      "source": [
        "Build a `tf.keras.Sequential`, starting with the `preprocessing_layer`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3mSGsHTFPvFo",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  preprocessing_layer,\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hPdtI2ie0lEZ"
      },
      "source": [
        "## Train, evaluate, and predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8gvw1RE9zXkD"
      },
      "source": [
        "Now the model can be instantiated and trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sW-4XlLeEQ2B",
        "colab": {}
      },
      "source": [
        "train_data = packed_train_data.shuffle(500)\n",
        "test_data = packed_test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q_nm28IzNDTO",
        "colab": {}
      },
      "source": [
        "model.fit(train_data, epochs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QyDMgBurzqQo"
      },
      "source": [
        "Once the model is trained, you can check its accuracy on the `test_data` set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eB3R3ViVONOp",
        "colab": {}
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sTrn_pD90gdJ"
      },
      "source": [
        "Use `tf.keras.Model.predict` to infer labels on a batch or a dataset of batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qwcx74F3ojqe",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(test_data)\n",
        "\n",
        "# Show some results\n",
        "for prediction, survived in zip(predictions[:10], list(test_data)[0][1][:10]):\n",
        "  print(\"Predicted survival: {:.2%}\".format(prediction[0]),\n",
        "        \" | Actual outcome: \",\n",
        "        (\"SURVIVED\" if bool(survived) else \"DIED\"))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egYLy-AIWsgy",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVvEJ6ZpWtgB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bec8e4c2-0af6-4f18-9cf5-eaab92537ef8"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPOZzAL7W0pe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21a5da80-8ff8-4bad-e5f6-f941e2a5bf9c"
      },
      "source": [
        "from __future__ import absolute_import, division, unicode_literals, print_function\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp2QG-hvW_jz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "512d1b1e-2499-459c-dbb4-b4923f22aa83"
      },
      "source": [
        "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
        "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
        "\n",
        "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
        "test_file_path = tf.keras.utils.get_file(\"eval.csv\", TEST_DATA_URL)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
            "16384/13049 [=====================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izq7ZKOnYNmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make numpy values easier to read\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwxtcj7PXil6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "351259b3-d277-4635-d31f-0bcef9b7856c"
      },
      "source": [
        "!head {train_file_path}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone\n",
            "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n",
            "1,female,38.0,1,0,71.2833,First,C,Cherbourg,n\n",
            "1,female,26.0,0,0,7.925,Third,unknown,Southampton,y\n",
            "1,female,35.0,1,0,53.1,First,C,Southampton,n\n",
            "0,male,28.0,0,0,8.4583,Third,unknown,Queenstown,y\n",
            "0,male,2.0,3,1,21.075,Third,unknown,Southampton,n\n",
            "1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n\n",
            "1,female,14.0,1,0,30.0708,Second,unknown,Cherbourg,n\n",
            "1,female,4.0,1,1,16.7,Third,G,Southampton,n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7NabO2HYYHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLUMN = 'survived'\n",
        "LABELS = [0,]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JfAtPqdIap-R",
        "colab": {}
      },
      "source": [
        "def get_dataset(file_path, **kwargs):\n",
        "    dataset = tf.data.experimental.make_csv_dataset(\n",
        "        file_path,\n",
        "        batch_size=5,\n",
        "        label_name=LABEL_COLUMN,\n",
        "        na_value=\"?\",\n",
        "        num_epochs=1,\n",
        "        ignore_errors=True,\n",
        "        **kwargs)\n",
        "    return dataset\n",
        "\n",
        "raw_train_data = get_dataset(train_file_path)\n",
        "raw_test_data = get_dataset(test_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLAJFb2rarNt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ee77f1b1-9010-4be1-b34b-7e4ab6df840b"
      },
      "source": [
        "print(raw_train_data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: (OrderedDict([(sex, (None,)), (age, (None,)), (n_siblings_spouses, (None,)), (parch, (None,)), (fare, (None,)), (class, (None,)), (deck, (None,)), (embark_town, (None,)), (alone, (None,))]), (None,)), types: (OrderedDict([(sex, tf.string), (age, tf.float32), (n_siblings_spouses, tf.int32), (parch, tf.int32), (fare, tf.float32), (class, tf.string), (deck, tf.string), (embark_town, tf.string), (alone, tf.string)]), tf.int32)>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: (OrderedDict([(sex, (None,)), (age, (None,)), (n_siblings_spouses, (None,)), (parch, (None,)), (fare, (None,)), (class, (None,)), (deck, (None,)), (embark_town, (None,)), (alone, (None,))]), (None,)), types: (OrderedDict([(sex, tf.string), (age, tf.float32), (n_siblings_spouses, tf.int32), (parch, tf.int32), (fare, tf.float32), (class, tf.string), (deck, tf.string), (embark_town, tf.string), (alone, tf.string)]), tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGzAojwra31w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_batch(dataset):\n",
        "    for batch, label in dataset.take(1):\n",
        "        for key, value in batch.items():\n",
        "            print(\"{:20s}: {}\".format(key, value.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znNE7ELRa8tV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "719b3a33-2fd7-4a9a-b125-97c9a94fb09d"
      },
      "source": [
        "show_batch(raw_train_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'male' b'female' b'male' b'male' b'male']\n",
            "age                 : [26. 30. 28.  4. 37.]\n",
            "n_siblings_spouses  : [0 0 0 4 2]\n",
            "parch               : [0 0 0 2 0]\n",
            "fare                : [  7.896 106.425   7.896  31.275   7.925]\n",
            "class               : [b'Third' b'First' b'Third' b'Third' b'Third']\n",
            "deck                : [b'unknown' b'unknown' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Cherbourg' b'Southampton' b'Southampton' b'Southampton']\n",
            "alone               : [b'y' b'y' b'y' b'n' b'n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ythIEBbcOD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "58d568be-6d61-4aa7-99e2-89e42ceef2b9"
      },
      "source": [
        "CSV_COLUMNS = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
        "\n",
        "temp_dataset = get_dataset(train_file_path, column_names=CSV_COLUMNS)\n",
        "\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'female' b'male' b'male' b'male' b'male']\n",
            "age                 : [14. 28. 32. 22. 34.]\n",
            "n_siblings_spouses  : [1 1 0 0 0]\n",
            "parch               : [0 0 0 0 0]\n",
            "fare                : [30.071 19.967 10.5    7.229  6.496]\n",
            "class               : [b'Second' b'Third' b'Second' b'Third' b'Third']\n",
            "deck                : [b'unknown' b'unknown' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Cherbourg' b'Southampton' b'Southampton' b'Cherbourg' b'Southampton']\n",
            "alone               : [b'n' b'n' b'y' b'y' b'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEKvPFGFc2Wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "dfa40f9b-f4f9-48a6-803a-f1b3f83745fa"
      },
      "source": [
        "# csv에서 데이터를 가져오는데 원하는 컬럼을 지정해서 가져올 수 있다\n",
        "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'class', 'deck', 'alone']\n",
        "\n",
        "temp_dataset = get_dataset(train_file_path, select_columns=SELECT_COLUMNS)\n",
        "\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age                 : [24. 48. 44. 28. 25.]\n",
            "n_siblings_spouses  : [0 1 1 0 0]\n",
            "class               : [b'Third' b'First' b'Second' b'Third' b'Third']\n",
            "deck                : [b'G' b'A' b'unknown' b'unknown' b'unknown']\n",
            "alone               : [b'n' b'n' b'n' b'n' b'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoeXjw8ijB1S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e1998827-53aa-4c98-a101-33605c887a21"
      },
      "source": [
        "# data format을 지정할 수 있다\n",
        "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'parch', 'fare']\n",
        "DEFAULTS = [0, 0.0, 0.0, 0.0, 0.0]\n",
        "temp_dataset = get_dataset(train_file_path,\n",
        "                           select_columns=SELECT_COLUMNS,\n",
        "                           column_defaults=DEFAULTS)\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age                 : [16.  19.  40.5 26.  24. ]\n",
            "n_siblings_spouses  : [0. 1. 0. 2. 0.]\n",
            "parch               : [0. 0. 2. 0. 0.]\n",
            "fare                : [ 8.05   7.854 14.5    8.663  7.142]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj1nC3MVj-D2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_batch, labels_batch = next(iter(temp_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtecdVifkD3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abb65c2d-b919-45c8-9f42-5cd91dddf14a"
      },
      "source": [
        "labels_batch"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 0, 0, 1], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JaNUs6MkMlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this function will pack together all the columns\n",
        "def pack(features, label):\n",
        "    return tf.stack(list(features.values()), axis=-1), label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZoxUrI3kVPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a0fa9050-3c9d-4342-83c0-fc988fb324b1"
      },
      "source": [
        "packed_dataset = temp_dataset.map(pack)\n",
        "\n",
        "for features, labels in packed_dataset.take(1):\n",
        "    print(features.numpy())\n",
        "    print()\n",
        "    print(labels.numpy())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 17.      0.      0.      7.125]\n",
            " [ 28.      0.      0.      7.229]\n",
            " [ 64.      1.      4.    263.   ]\n",
            " [ 45.      0.      0.      6.975]\n",
            " [ 28.      1.      1.     15.246]]\n",
            "\n",
            "[0 1 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70zo5aRBk-ho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39252d5a-fb44-409d-9c1d-23992d59f9b6"
      },
      "source": [
        "print(packed_dataset)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MapDataset shapes: ((None, 4), (None,)), types: (tf.float32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8RowC1-lCLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0a2ca6ee-5cf6-4110-fc89-671b4b2d08d3"
      },
      "source": [
        "show_batch(raw_train_data)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'male' b'male' b'male' b'male' b'male']\n",
            "age                 : [28. 25. 20. 28. 25.]\n",
            "n_siblings_spouses  : [0 0 0 0 0]\n",
            "parch               : [0 0 0 0 0]\n",
            "fare                : [ 8.05  13.     7.229  8.05   7.05 ]\n",
            "class               : [b'Third' b'Second' b'Third' b'Third' b'Third']\n",
            "deck                : [b'unknown' b'unknown' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Southampton' b'Cherbourg' b'Southampton' b'Southampton']\n",
            "alone               : [b'y' b'y' b'y' b'y' b'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YINcmJgXlN3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_batch, labels_batch = next(iter(temp_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7WuC2OclU-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PackNumericFeatures(object):\n",
        "    def __init__(self, names):\n",
        "        self.names = names\n",
        "    \n",
        "    def __call__(self, features, labels):\n",
        "        numeric_features = [features.pop(name) for name in self.names]\n",
        "        numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "        numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "        features['numeric'] = numeric_features\n",
        "\n",
        "        return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eyil6JOZl0-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUMERIC_FEATURES = ['age', 'n_siblings_spouses', 'parch', 'fare']\n",
        "\n",
        "packed_train_data = raw_train_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES)\n",
        ")\n",
        "\n",
        "packed_test_data = raw_test_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH4iTgGdmK-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "93be92e7-e5f2-4a9d-e3c5-4547c12d3437"
      },
      "source": [
        "show_batch(packed_train_data)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'male' b'female' b'male' b'female' b'male']\n",
            "class               : [b'Third' b'First' b'Third' b'First' b'Third']\n",
            "deck                : [b'unknown' b'B' b'unknown' b'B' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Cherbourg' b'Queenstown' b'Southampton' b'Southampton']\n",
            "alone               : [b'y' b'y' b'y' b'n' b'y']\n",
            "numeric             : [[ 28.      0.      0.      8.05 ]\n",
            " [ 58.      0.      0.    146.521]\n",
            " [ 28.      0.      0.      7.829]\n",
            " [ 17.      1.      0.     57.   ]\n",
            " [ 28.      0.      0.      7.05 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8d5NNiomR1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_batch, labels_batch = next(iter(packed_train_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rHzqKQJnGuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "1d9e07c5-5a3d-434f-eb7a-6517d7626f8b"
      },
      "source": [
        "import pandas as pd\n",
        "desc = pd.read_csv(train_file_path)[NUMERIC_FEATURES].describe()\n",
        "desc"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>29.631308</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.379585</td>\n",
              "      <td>34.385399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.511818</td>\n",
              "      <td>1.151090</td>\n",
              "      <td>0.792999</td>\n",
              "      <td>54.597730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age  n_siblings_spouses       parch        fare\n",
              "count  627.000000          627.000000  627.000000  627.000000\n",
              "mean    29.631308            0.545455    0.379585   34.385399\n",
              "std     12.511818            1.151090    0.792999   54.597730\n",
              "min      0.750000            0.000000    0.000000    0.000000\n",
              "25%     23.000000            0.000000    0.000000    7.895800\n",
              "50%     28.000000            0.000000    0.000000   15.045800\n",
              "75%     35.000000            1.000000    0.000000   31.387500\n",
              "max     80.000000            8.000000    5.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7VEnESqnR8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MEAN = np.array(desc.T['mean'])\n",
        "STD = np.array(desc.T['std'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7C3C2--nWdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "34f41e3b-4f59-4861-818e-496640baf173"
      },
      "source": [
        "print(MEAN)\n",
        "print(STD)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[29.631  0.545  0.38  34.385]\n",
            "[12.512  1.151  0.793 54.598]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ5Jq0QLnnSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_numeric_data(data, mean, std):\n",
        "    # Center the data\n",
        "    return (data-mean)/std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvgST6-fn1Ex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b357202e-f608-4e36-8d1b-c920fa0f3ab0"
      },
      "source": [
        "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
        "\n",
        "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
        "numeric_columns = [numeric_column]\n",
        "numeric_column"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NumericColumn(key='numeric', shape=(4,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function normalize_numeric_data at 0x7f2a60fe4bf8>, mean=array([29.631,  0.545,  0.38 , 34.385]), std=array([12.512,  1.151,  0.793, 54.598])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFH6l6kSoNNF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4a767ad7-0966-4a99-9589-546613c571bf"
      },
      "source": [
        "example_batch['numeric']"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[ 23.   ,   0.   ,   0.   ,  10.5  ],\n",
              "       [ 20.   ,   0.   ,   0.   ,   9.846],\n",
              "       [ 27.   ,   0.   ,   2.   , 211.5  ],\n",
              "       [ 22.   ,   0.   ,   0.   ,   9.   ],\n",
              "       [ 28.   ,   0.   ,   1.   ,  55.   ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YXCjHw2odpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3791f1a9-c337-463f-9f39-d81b76d21d4f"
      },
      "source": [
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
        "numeric_layer(example_batch).numpy()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.53 , -0.474, -0.479, -0.437],\n",
              "       [-0.77 , -0.474, -0.479, -0.449],\n",
              "       [-0.21 , -0.474,  2.043,  3.244],\n",
              "       [-0.61 , -0.474, -0.479, -0.465],\n",
              "       [-0.13 , -0.474,  0.782,  0.378]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BCswnfOorcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CATEGORIES = {\n",
        "    'sex': ['male', 'female'],\n",
        "    'class' : ['First', 'Second', 'Third'],\n",
        "    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
        "    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
        "    'alone' : ['y', 'n']\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPR4ucOsoxtD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6dd59326-0452-4caf-d975-ab84e3c10c5e"
      },
      "source": [
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "    print(feature, vocab)\n",
        "\n",
        "    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "    categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex ['male', 'female']\n",
            "class ['First', 'Second', 'Third']\n",
            "deck ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
            "embark_town ['Cherbourg', 'Southhampton', 'Queenstown']\n",
            "alone ['y', 'n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHIxSmgEpUqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f7002464-9318-4949-e462-f4072bb50874"
      },
      "source": [
        "categorical_columns"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('First', 'Second', 'Third'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Cherbourg', 'Southhampton', 'Queenstown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('y', 'n'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyROT8hppXf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "57fb675a-703e-40e5-f211-aa21ebaa2540"
      },
      "source": [
        "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
        "print(categorical_layer(example_batch).numpy()[0])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVKpPRrlp0BE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0v7KjIgp7sw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "d153f03a-3552-4c67-f980-0de14e7de69b"
      },
      "source": [
        "print(preprocessing_layer(example_batch).numpy())"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.     0.     0.     1.     0.     0.     0.     0.     0.     0.\n",
            "   0.     0.     0.     0.     0.     0.     0.     0.    -0.53  -0.474\n",
            "  -0.479 -0.437  1.     0.   ]\n",
            " [ 1.     0.     0.     0.     1.     0.     0.     0.     0.     0.\n",
            "   0.     0.     0.     0.     0.     0.     0.     0.    -0.77  -0.474\n",
            "  -0.479 -0.449  1.     0.   ]\n",
            " [ 0.     1.     1.     0.     0.     0.     0.     1.     0.     0.\n",
            "   0.     0.     0.     0.     0.     1.     0.     0.    -0.21  -0.474\n",
            "   2.043  3.244  1.     0.   ]\n",
            " [ 1.     0.     0.     0.     1.     0.     0.     0.     0.     0.\n",
            "   0.     0.     0.     0.     0.     0.     0.     0.    -0.61  -0.474\n",
            "  -0.479 -0.465  1.     0.   ]\n",
            " [ 0.     1.     1.     0.     0.     0.     0.     0.     0.     1.\n",
            "   0.     0.     0.     0.     0.     0.     0.     0.    -0.13  -0.474\n",
            "   0.782  0.378  0.     1.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JZnyoBrqAOH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "76061709-28a7-4146-e2cf-9372debc7368"
      },
      "source": [
        "example_batch"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('sex',\n",
              "              <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'male', b'male', b'male', b'male', b'female'], dtype=object)>),\n",
              "             ('class',\n",
              "              <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'Second', b'Third', b'First', b'Third', b'First'], dtype=object)>),\n",
              "             ('deck',\n",
              "              <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'unknown', b'unknown', b'C', b'unknown', b'E'], dtype=object)>),\n",
              "             ('embark_town', <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
              "              array([b'Southampton', b'Southampton', b'Cherbourg', b'Southampton',\n",
              "                     b'Southampton'], dtype=object)>),\n",
              "             ('alone',\n",
              "              <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'y', b'y', b'n', b'y', b'n'], dtype=object)>),\n",
              "             ('numeric', <tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "              array([[ 23.   ,   0.   ,   0.   ,  10.5  ],\n",
              "                     [ 20.   ,   0.   ,   0.   ,   9.846],\n",
              "                     [ 27.   ,   0.   ,   2.   , 211.5  ],\n",
              "                     [ 22.   ,   0.   ,   0.   ,   9.   ],\n",
              "                     [ 28.   ,   0.   ,   1.   ,  55.   ]], dtype=float32)>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrdpFrhPqJPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    preprocessing_layer,\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Eq7dMnqqpxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = packed_train_data.shuffle(500)\n",
        "test_data = packed_test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN-vBqInqv3m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "29137a58-8ca1-404b-bf5e-223e04c40c55"
      },
      "source": [
        "model_history = model.fit(train_data, epochs=20)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "126/126 [==============================] - 1s 6ms/step - loss: 0.3050 - accuracy: 0.8756\n",
            "Epoch 2/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8676\n",
            "Epoch 3/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.3017 - accuracy: 0.8676\n",
            "Epoch 4/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8740\n",
            "Epoch 5/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.8820\n",
            "Epoch 6/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2968 - accuracy: 0.8820\n",
            "Epoch 7/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2906 - accuracy: 0.8836\n",
            "Epoch 8/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2924 - accuracy: 0.8772\n",
            "Epoch 9/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2824 - accuracy: 0.8836\n",
            "Epoch 10/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.8836\n",
            "Epoch 11/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.8740\n",
            "Epoch 12/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.8820\n",
            "Epoch 13/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.8724\n",
            "Epoch 14/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2748 - accuracy: 0.8772\n",
            "Epoch 15/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.8868\n",
            "Epoch 16/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.8820\n",
            "Epoch 17/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2694 - accuracy: 0.8947\n",
            "Epoch 18/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2675 - accuracy: 0.8852\n",
            "Epoch 19/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.8915\n",
            "Epoch 20/20\n",
            "126/126 [==============================] - 0s 3ms/step - loss: 0.2733 - accuracy: 0.8820\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAjU4JZsq5w2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "fb584381-60b8-4633-ad86-978787d594a6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(model_history.history['loss'])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2a5cbfdf98>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXzU1b3/8ddnZjLZCAlLyMaasAYC\nqJEdxLKDgN2stlq9tuXq7aK13tZWbxd77+1V295bb63Wq/1V6651AWUTRWTXsCZhDVsgZGVJSEL2\n8/tjJnQICZkks+fzfDx4MPNdPwyTd2bO93zPEWMMSimlQpfF3wUopZTyLg16pZQKcRr0SikV4jTo\nlVIqxGnQK6VUiLP5u4CW+vbtawYPHuzvMpRSKqjs2LGjzBgT39q6gAv6wYMHk5WV5e8ylFIqqIjI\nibbWadONUkqFOA16pZQKcRr0SikV4jTolVIqxGnQK6VUiNOgV0qpEKdBr5RSIS5kgr66roHHVh/g\n5Nlqf5eilFIBJWSCvvxiPS9uOc4j7+agY+wrpdQ/hEzQJ8VG8qO5I9hwqJQPsgv9XY5SSgWMkAl6\ngDunDCYjJZZfrdhH+cV6f5ejlFIBIaSC3moR/vOLGZyprOWJNQf8XY5SSgWEkAp6gIz+sdw1ZQgv\nb89nx4lz/i5HKaX8LuSCHuBHc4eT1DOCn72dTX1jk7/LUUopvwrJoI8Ot/GrpWM4WHyB5zYe83c5\nSinlVyEZ9ABz0hOYNzqBP3x0iPwz2rdeKdV9hWzQA/xyyWisIjzynvatV0p1XyEd9EmxkTw4bwSf\nHirl/b3at14p1T2FdNADfHOyS9/6au1br5TqfkI+6K0W4TdfyuBsVS2Pad96pVQ3FPJBDzAmJZa7\npw7hle357Dhx1t/lKKWUT3WLoAf44ZzhJMdG8LO3c7zSt76uoYlXtudTcP6ix4+tlFJd0W2CPjrc\nxqPOvvX/t/GoR499rKyKrzyzhZ+9k803n99ORY1eC1BKBY5uE/QAs9MTmD86kT+sO+yxvvVv7zzF\nTU9u5MSZah6YM5wTZ6r5/iu7aNA7cpVSAaJbBT04+taHWS08/G52l/rWX6ip5/7XdvHAG3sYnRLL\nqvum84NZw/j1zWPYcKiU36zSC79KqcDQ7YI+MTaCB+cOZ+PhMpbvOd2pY+zKP8eiJzexYm8hP5oz\nnFe/M4nkuEgAbpswkLumDOb5Tcd4/fN8T5aulFKd0u2CHuCOyYMZ2z+WX7/fsb71TU2GP32Sx1ef\n2Upjk+H1ZZP4/qxhWC1y2XaPLBrF9GF9eeTdHLYfPePp8pVSqkO6ZdA3j1t/rrqe/1rtXhNLcUUN\nd/xlO4+vPsi80YmsvG86mYN7t7qtzWrhj1+/lgG9orj35Z06j61Syq+6ZdBDc9/6wbz6WT5Zx6/e\nt/6j/cUs+MNGdp44z2NfzuCPX7+G2Miwq+4TGxnGc3dm0tDYxLdfyKKytsGT5SullNu6bdAD3D97\nOClxkfzsnWzqGq7sJVNT38gvl+fyrReySOwZwYrvT+Nr1w9ERFo52pVS43vwp29cR15pJfe/tovG\nJh1YTSnle24FvYjMF5GDIpInIg+1sv4eEckWkd0isklE0l3W/dS530ERmefJ4rvK0bd+NIeKK6/o\nW59XcoEv/mkLf91ynLunDuGd705haL8eHT7HtGF9+cXidNbtL+GJNQc9VbpSSrnN1t4GImIFngLm\nAKeAz0VkuTFmn8tmrxhjnnFuvwT4PTDfGfi3AqOBZGCdiAw3xjR6+N/RabNGJbBgTCJPfnSYm8Ym\nMbB3FK9/fpJfrsglym7jL3dl8oWRCV06xx2TBnGw6ALPbDjC8IQefOna/h6qXiml2tdu0AMTgDxj\nzFEAEXkNWApcCnpjTIXL9tFAcxvFUuA1Y0wtcExE8pzH2+qB2j3mF4tHs/FwGT99O5teUXY+yC5k\n2tC+/P6WcfTrGdHl44sIv1wymqOlVTz092wG943m2oG9PFC5Ukq1z52mmxTgpMvzU85llxGR74rI\nEeBx4Acd3HeZiGSJSFZpaam7tXtMYmwE/zpvBFuOnGFNbhEPLRjJi3dP8EjINwuzWvjTN64lKS6C\nZS/u0DFxlFI+47GLscaYp4wxacBPgEc6uO+zxphMY0xmfHy8p0rqkNsnDeKhBSP5+71TuOeGNCwW\n9y64dkSvaDvP35lJbX0j33khi+o67YmjlPI+d4K+ABjg8ry/c1lbXgNu7uS+fmO1CPfckMa4AXFe\nPc/QfjE8+fVrOFBUwY/e2EOT9sRRSnmZO0H/OTBMRIaIiB3HxdXlrhuIyDCXp4uAw87Hy4FbRSRc\nRIYAw4DPul52cLtxRD9+tnAUq3KK+J91h/xdjlIqxLV7MdYY0yAi3wPWAFbgL8aYXBF5FMgyxiwH\nvicis4F64Bxwp3PfXBF5A8eF2wbgu4HU48afvjVtCIeKL/Dkx3kMS4hh8bhkf5eklApR0pURHL0h\nMzPTZGVl+bsMn6hraOL257az59R53rxnMmP7e7fZSCkVukRkhzEms7V13frOWH+z2yw8ffu19O0R\nzndezKKovMbfJSmlQpAGvZ/16RHO83dlUlnTwLK/ZVFTry1bSinP0qAPACMTe/I/t15DdkE5j6/W\nYRKUUp6lQR8g5qQncNuEgby49Th5JRf8XY5SKoRo0AeQH80ZTqTdyqPv7+/SNIdKKeVKgz6A9OkR\nzv2zh/PpoVLWHyzxdzlKqRChQR9gvjl5EKnx0fz6/f2tjpGvlFIdpUEfYMKsFv7tpnSOlVXxwpbj\n/i5HKRUCNOgD0I0j+nHjiHie/OgwpRdq/V2OUirIadAHqEduSudifSO/W6vdLZVSXaNBH6DS4ntw\n15TBvJ51kpyCcn+Xo5QKYhr0Aez7s4bRO8rOoyv2aXdLpVSnadAHsNjIMB6cN4LPjp/lg+xCf5ej\nlApSGvQB7pbMAaQn9eQ3Kw9wsU7HwVFKdZwGfYCzWoRfLE6n4PxFnv30qL/LUUoFIQ36IDAxtQ+L\nMpJ4ekMep3VScaVUB2nQB4mHFozEGPivVQf8XYpSKsho0AeJAb2j+OcZqSzfc5rPj5/1dzlKqSCi\nQR9E7pmZRmLPCH61IpemJu1uqZRyjwZ9EImy2/jpwpHkFFTw1o5T/i5HKRUkNOiDzJJxyVw3qBeP\nrznAhZp6f5ejlAoCGvRBRsTR3bKsso4/fpzn73KUUkFAgz4Ije0fx1ev689fNh/jWFmVv8tRSgU4\nDfog9a/zR2C3WviPD/b5uxSlVIDToA9S/WIi+P6sYazbX8KGQ6X+LkcpFcA06IPYP00dzKA+Ufz6\n/X3UN+q0g0qp1mnQB7Fwm5WHF44ir6SSl7ad8Hc5SqkApUEf5OakJzBtaF/++8NDnK2q83c5SqkA\npEEf5ESEf7spnaq6Rn7/oU47qJS6kgZ9CBiRGMPtEwfyyvZ8dpzQcXD85cE39/DqZ/n+LkOpK2jQ\nh4gfzhlO3x7hfPWZrfz07WzKKmv9XVK3kn+mmrd2nOKp9Xk67aMKOBr0ISIuys6a+2fwzcmDeTPr\nJDOf+ISnPzlCTb3OSuULq3MdUz2eOneRnfnn/VyNUpfToA8hvaLt/HLJaNb8cAYTh/TmsdUHmP37\nDXywt1A/ZXrZ6pwi0uKjCbdZWL67wN/lKHUZDfoQlBbfg+fvup6XvjWRHuE2vvvKTm7581b2nNRP\nmt5QVF7DzvzzfPGaFGaPSuD9vYU06H0NKoBo0IewacP68sEPpvObL2VwrKyKpU9t5oHXd1NYrtMR\netLafUUAzB+TyJLxyZypqmPzkTN+rkqpf9CgD3FWi3DbhIGsf3Am985M4/3sQm787Sf8/sNDVNc1\n+Lu8kNDcbDO0XwwzR8QTE2HjPW2+UQHEraAXkfkiclBE8kTkoVbWPyAi+0Rkr4h8JCKDXNY9JiI5\nzj9f82Txyn0xEWH8ZP5IPnrgBmaNSuDJjw5z428/4a0dp3S2qi44W1XH9mNnWTAmCXDcrbxwTBJr\ncor0QrgKGLb2NhARK/AUMAc4BXwuIsuNMa7DJu4CMo0x1SJyL/A48DURWQRcC4wHwoFPRGSVMabC\n0/8Q5Z4BvaN46uvXcvfUszz6/n4efHMPL2w5zr/dlM6EIb07dCxjDHWNTVTVNlJV20B1XSNNxiAC\nFhEsAuD42yJyabmI40avS8txPLdahF5RYYiIN/7pXrFuXzGNTYb5YxIvLVs6PpnXs07y0f4SFo1N\n8mN1Sjm0G/TABCDPGHMUQEReA5YCl4LeGLPeZfttwO3Ox+nAp8aYBqBBRPYC84E3PFC76oLrBvXm\nnXunsHzPaR5bfYBb/ryVBWMSuXZgL6rqHKFdWdtAdW0DlbWNVNc1UFXnDPTafzxu8PC3gftnD+P+\n2cM9ekxvWp1bRP9ekYxO7nlp2cTUPvSLCee93QUa9CoguBP0KcBJl+engIlX2f5bwCrn4z3AL0Tk\nd0AUcCMuvyCaicgyYBnAwIED3ShJeYLFItx8TQrzRify3MajPL3hCKtyHBcWI8OsRIdbiQ63EWW3\nEW23EhcZRkpcBFF2Gz3CbUTZHeuj7Vaiwm1E221YLdBkwBhoMoYmZ7fOJmNoagLjfGyMcW7jfA68\nlXWSN7NOcd+sYUHxqf5CTT2bDpfxzcmDLqvXahEWj0vmb1tPUF5dT2xUmB+rVMq9oHebiNwOZAI3\nABhj1orI9cAWoBTYClzRcGmMeRZ4FiAzM1MbjH0s0m7l+7OG8Z0ZqdQ3NhFlt2G1+D5oo+1WHnhj\nDzvzz3HdoI41I/nDxwdKqGtsuqzZptnS8ck8v+kYq3ML+dr1+uFF+Zc7F2MLgAEuz/s7l11GRGYD\nDwNLjDGX7r83xvyHMWa8MWYOIMChrpWsvCUizEpMRJhfQh4cI3GG2yys2FPol/N31JrcIuJjwrl2\nYK8r1mWkxDKkbzTv7T7th8qUupw7Qf85MExEhoiIHbgVWO66gYhcA/wZR8iXuCy3ikgf5+OxwFhg\nraeKV6ElJiKML4zsx/t7C2kM8J5ANfWNrD9QyrzRCVha+cUoIiwZl8zWo2corqjxQ4VK/UO7Qe+8\nkPo9YA2wH3jDGJMrIo+KyBLnZk8APYA3RWS3iDT/IggDNorIPhxNM7c7j6dUqxaPS6asspZtRwP7\nhqMNh0q5WN/I/NFtX2xdMj4ZY2DFHv1Ur/zLrTZ6Y8xKYGWLZT93eTy7jf1qcPS8UcotXxjZj2i7\nlRV7TjN1aF9/l9OmNTlFxEaGMTG17WsJafE9yEiJZfme03x7eqoPq1PqcnpnrAooEWFW5o5OZFVO\nEXUNgTleTF1DE+v2FzMnPYEw69V/hJaOT2bvqXKOllb6qDqlrqRBrwLO4nFJlF+sZ+PhUn+X0qqt\nR89QUdPA/NFX9rZp6aaxyYjAcm2+UX6kQa8CzrSh8cRFhQVs2/bqnCKi7VamDWu/aSkxNoJJQ/qw\nfPdpHSpa+Y0GvQo4dpuFBWMSWbuvmIt1gTVeTGOT4cN9Rdw4sh8RYVa39lk6PpmjZVXkFOjIH8o/\nNOhVQFo8NpnqukY+PlDS/sY+lHX8LGWVda3eJNWWBWOSCLOKjmip/EaDXgWkial9iI8JZ/mewArH\n1blF2G0WZo7o5/Y+sVFhzBzRjxV7Twf8/QEqNGnQq4BktQiLMpJYf7CUipp6f5cDOEbrXJNTxIxh\nfekR3rHRQ5aOT6a4opbtxwL7/gAVmjToVcBaMj6ZuoYmPswt9ncpAOw9Vc7p8hrmj+n4iJSzRiYQ\nbbeyXIdEUH6gQa8C1jUD4kiJiwyYromrc4uwWoTZo9xvtmkWabcyb3QiK7MLqW0IrAvMKvRp0KuA\nJeIY7ndTXhlnq+r8WosxhtU5RUxO7UNclL1Tx1gyPpmKmgY+ORiY9weo0KVBrwLaknHJNDYZVmb7\nd0TLwyWVHCur6lBvm5amDu1Ln2i7Nt8on9OgVwFtVFIMafHRfr95alV2ESIwNz2h08cIs1pYNDaJ\ndfuLuRAgF5hV96BBrwKaY7jfFD47fpaicv8N97s6t4jrBvaiX8+ILh1n6fhkahuaWBsgF5hV96BB\nrwLeTeOSMAbe3+ufT/UnzlSxv7CiS802za4d2Iv+vSJ5L0AuMKvuQYNeBby0+B6MTu7Jir3+aadf\n7ZxHd54bg5i1R0RYOj6ZzXlllF6obX8HpTxAg14FhSXjktlz8jz5Z6p9fu7VuUWMSenJgN5RHjne\n0vEpAXGBWXUfGvQqKNw0LhmAFT5uvikqr2FX/nkWdOImqbYMT4hhZGKMjn2jfEaDXgWFlLhIMgf1\n8nnvmzW5nmu2cbV0fAo78/3zDUV1Pxr0KmgsHpfMgaILHCq+4LNzrs4pYmi/Hgzt18Ojx108zvEN\nwdffUFT3pEGvgsbCjCQs4rvJts9W1bH92BkWeKC3TUv9e0Vx/eBevLurQCckUV6nQa+CRnxMOFPS\n+rJij29ma/pwXxFNxvPNNs2WjE/hcEklB4p89w1FdU8a9CqoLB6XxPEz1WQXlHv9XKtziujfK5LR\nyT29cvxFGUnYLMJ7OiSC8jINehVU5o92zNbk7eabipp6Nuc5mm1ExCvn6B1tZ/owxzeUJp2QRHmR\nBr0KKrFRYdwwPJ739xZ6NRzXHyihrrHJI3fDXs3S8SkUnL/IjvxzXj2P6t406FXQWTwumcLyGrJO\neC8cV+cUER8TzjUDenntHABz0hOICLNon3rlVRr0KujMHuUIR28131ysa+STg6XMG52AxeKdZptm\n0eE25qQn8sHeQuobm7x6LtV9adCroBMdbmPWqARWZhfS4IVw/PRwKRfrGz16N+zVLB2XzLnqejYd\nLvPJ+VT3o0GvgtLiscmcqapjyxHPT7a9OqeIuKgwJgzp7fFjt2bG8HhiI8O0+UZ5jQa9CkozR8QT\nE27z+HyydQ1NrNtfzOxRCYRZffPjYbdZWJiRxNp9xVTXNfjknKp70aBXQSkizMrc0YmsySny6GTb\nW4+e4UJNg1fuhr2apeOTqa5r5K9bjpNXUkllrQa+8hybvwtQqrOWjE/m7ztPseFgKXM9dPfq6pxC\nou1Wpg7t65HjuWvC4N707xXJ46sP8vjqgwBE260k9IygX89wEnpGOB7HOB4nxkaQEONYFxFm9Wmt\n3nLvSzuIjwnn0aVj/F1KyNGgV0FrSlofekfbWb7ntEeCvrHJsDa3mBtH9vN5eFoswnvfncrB4guU\nVNRSXFFDcUUtxRdqKKlwDJVcXFFDbcOVF59jI8NIcP4yuHPyYGZ3YV5bfzlYdIFVOUVEhln56YJR\nRNpD45dXoNCgV0ErzGphwZhE3t5ZQHVdA1H2rr2ds46f5UxVnc9627TUp0c4U3qEt7neGEPFxQaK\nL9T84xdBRc2lPzkFFdz/+m4+fGAGSbGRPqy8617adgKAi/WNfHKwhAUZ/vk/CFUa9CqoLRmXzMvb\n8/lwXzFLx6d06Virc4uw2yzMHBHvoeo8S0SIjQojNiqM4QkxV6zPP1PNnP/ewK+W7+OZO67zQ4Wd\nU1nbwDu7Clg6PplNh8v4ILtQg97D9GKsCmrXD+5NYs8IVuzp3LR8NfWNrM0t4r7XdvHK9nxmDIsn\nOjw4P/8M7BPFfbOHsTq3iA/3Ffu7HLe9u6uAytoG7pwymLmjE/n4QAk19Z67wK7cDHoRmS8iB0Uk\nT0QeamX9AyKyT0T2ishHIjLIZd3jIpIrIvtF5Enx1ghRqluyWISbxiax4VAJ5dX1bu1T29DIun3F\n/PD13WT++zqW/W0Hnx4q5UvXpvCrpaO9XLF3fWd6KiMSYvjFezlUBUHPHWMML207wejknlwzII5F\nGUlUO+9MVp7TbtCLiBV4ClgApAO3iUh6i812AZnGmLHAW8Djzn2nAFOBscAY4HrgBo9VrxSOsW/q\nG82laf9aU9vQyEf7i3ng9d1k/nod334xi/UHS1iUkcSLd0/gs4dn85svjSUlLrjatlsKs1r4zy+N\n4XR5Df/94SF/l9OuHSfOcaDoArdPGoSIMCm1N72iwliVoxOne5I731EnAHnGmKMAIvIasBTY17yB\nMWa9y/bbgNubVwERgB0QIAwInu+UKiiM7R/LoD5RrNh7mluuH3BpeV1DE5vzynh/byFr9xVxoaaB\n2MgwFmQksmhsMlPS+vjspihfum5Qb74+cSB/2XyMm69JYUxKrL9LatNL204QE25j6XjH5O82q4V5\noxN5f28hNfWNIdN11N/cCfoU4KTL81PAxKts/y1gFYAxZquIrAcKcQT9H40x+1vuICLLgGUAAwcO\ndK9ypZxEhMVjk/nTJ3kUll/kQNEFPthbyNrcIipqGugZYWPe6EQWjU1ialpf7LbQC/eWfjJvJGtz\ni/nZO9m88y9TsXp5cLbOKKusZWV2EV+fOPCyHlMLM5J47fOTfHrIc/dHdHceveokIrcDmTibZ0Rk\nKDAK6O/c5EMRmW6M2ei6nzHmWeBZgMzMTJ2BQXXY4nHJ/HF9HjMeX099oyEmwsbc9ERuGpvE1KHd\nI9xdxUaF8fPF6fzg1V38betx7po6xN8lXeGNrJPUNTZx+6TLP9xNTutDXFQYq3KKNOg9xJ2gLwAG\nuDzv71x2GRGZDTwM3GCMqXUu/iKwzRhT6dxmFTAZ2Nhyf6W6YkRiDF/LHEB9YxOLxiYxbVhfwm3d\n+2v/4rFJvLXjFL9de4h5YxIDqm99Y5Phle35TErtzdB+l3cVDbNamJuewKpsx/AW3f3/0RPc+Zjz\nOTBMRIaIiB24FVjuuoGIXAP8GVhijClxWZUP3CAiNhEJw/FJ/4qmG6U84bGvjOX3XxvPrFEJGg44\nmrT+fekY6hub+NXyfe3v4EMbDpVw6txF7pg0uNX1CzOSuFDbwMZDOnSzJ7Qb9MaYBuB7wBocIf2G\nMSZXRB4VkSXOzZ4AegBvishuEWn+RfAWcATIBvYAe4wxKzz9j1BKtS5Q+9a/tC2f+Jhw5o5ufbiG\nKWl96RlhY6X2vvEIt9rojTErgZUtlv3c5fHsNvZrBP65KwUqpbrmO9NTeW/XaX7xXg5T0vr4/Yaw\nk2erWX+whO/fOLTNXk92m8UxOmmuNt94Qve6QqVUNxRofetf3p6PRYTbJl69h92ijCQu1DSwJc/z\nk8t0Nxr0SnUDrn3rcwrK/VZHbUMjb2SdZNbIfu1eHJ46tC8xETY+yNbmm67SoFeqm/jJvJH0jg7n\nZ+9k09jkn17Mq7KLOFtVxx2TB7W7rd1mYU56Amtzi6hrZXhm5T4NeqW6iea+9XtPlV8aFtjXXtp2\ngiF9o5ma5t7ELgvHJFFR08CWI9r7pis06JXqRhaPTWLG8HieWHOQovIan557f2EFWSfO8Y2JA7G4\neafu9OF9iQm3sVKbb7pEg16pbuSyvvUrcn167pe2nSDcZuEr1/Vvf2OncJuV2ekJrN1XTH2jNt90\nlga9Ut1Mc9/6VTlFrPNR3/oLNfW8s6uAxeOSiYuyd2jfBWMSOV9dz9Yj2vumszToleqGLo1bvzzX\nJ+PWv7OrgOq6Ru6Y1P5F2JZmDI8n2m7V5psu0KBXqhtq7ltfcP4i/7POu33rmycXyUiJZdyAuA7v\nHxFmZdaoBNbkFtGgzTedokGvVDf1j771x73at/6zY2c5VFzZqU/zzRZmJHGuup5tR896sLLuQ4Ne\nqW7sJ/NG0ivKzsNe7Fv/0vZ8ekbYWDwuudPHmDkinii7VW+e6iQNeqW6sea+9Xu81Le+9EItq3MK\n+cp1A4i0d368mogwK18Y2Y+12nzTKRr0SnVz3uxb/0bWSeobDd+Y1PWZ4xZlJHGmqo7PjmnzTUdp\n0CvVzbn2rV/2tyxOnq32yHEbmwwvbzvB1KF9SIvv0eXjzRzRj8gwqw5d3Aka9EopBvaJ4n9vu4Zj\npVUsenIjqz0Qph8fKOF0eU2XLsK6irQ7mm9W5xT7bayeYKVBr5QCYO7oRD74wXSG9I3mnpd28ov3\ncqipb+z08V7adoKEnuHMHtX65CKdsTAjibLKWm2+6SANeqXUJQP7RPHmPVP49rQhvLD1BF9+egvH\nyqo6fJwTZ6rYcKiU2yYMxNbG5CKdcePIeCLCLKzS5psO0aBXSl3GbrPwyE3pPPfNTArOX+SmJzfy\n3u6CDh3jle35WC3CbRO6fhHWVZTdxo0j+rEqpyjkmm9+tSKXn7y11yvH1qBXSrVqdnoCK38wnVFJ\nPbnvtd389O29XKxrvymnpt4xucjc9AQSekZ4vK6FGUmUXqhlx4lzHj+2vxhjWJVdRKWXhqPQoFdK\ntSk5LpLXlk3iX2am8epnJ7n5qc0cLr5w1X1WZhdyrrreYxdhW/rCyH6E2ywhNfbNkdIqiipqmDrU\nvXH6O0qDXil1VTarhR/PH8kLd0+grLKWJX/czJtZJzGm9aaTv207QWp8NJPT+nilnuhwGzNHxLMq\np5CmEGm+2ZznmFhl+jANeqWUH90wPJ5V901n/IA4/vWtvfzojT1XjHyZU1DOrvzz3D5xECLuTS7S\nGQszkiiuqGVnfmg032w8XMbA3lEM6B3lleNr0Cul3NavZwQvfXsiP5w9nHd3F7D4fzex73TFpfUv\nbz9BRJiFL3dgcpHOmDUqAbvNEhJj3zQ0NrHt6BmvNduABr1SqoOsFuG+2cN4+duTqKxt4OY/beal\nbScov1jPu7tOs3RcCrGRYV6toUe4zfENI7so6Jtv9pw6T2Vtg9eabUCDXinVSZPT+rDqvulMTu3D\nI+/m8MWnNnOxvpE7JnvnImxLCzMSKaqoYdfJ8z45n7dsOnwGEZic6p1rGqBBr5Tqgj49wvl/d13P\nQwtGcuJsNeMHxDEmJdYn5541KgG7Nfh732zOKyMjJZZe0R2bYrEjbF47slKqW7BYhHtuSGNOegIx\n4b6LlJ4RYcwY3pdV2YU8smiUVy/+ektlbQM788/xnRmpXj2PfqJXSnlEWnwP+nnhBqmrWTAmidPl\nNewO0uabz46doaHJMM2LF2JBg14pFcRmpycQZpWgbb7ZeLiMcJuF6wb18up5NOiVUkErNjKMaUP7\nsjK7qM0buALZ5rwyJgzpTURY52ffcocGvVIqqC3MSKLg/EX2nvLeBOfeUFJRw6HiSq8324AGvVIq\nyM1NT8RmkaCbeWqTc9gDb6yiHwIAAA4RSURBVN4o1UyDXikV1GKjwpg6tC8rswuDqvlmU14ZvaPt\npCf19Pq5NOiVUkFvUUYSJ89eJKegov2NA4Axhk2Hy5iS1geLxfvdQjXolVJBb+7oBGwW4ZXPTgTF\nhCR5JZWUXKj1Sfs8uBn0IjJfRA6KSJ6IPNTK+gdEZJ+I7BWRj0RkkHP5jSKy2+VPjYjc7Ol/hFKq\ne4uLsrNkXDKvfnaSBX/4lDW5gd0LZ+NhR/v8NC+Ob+Oq3aAXESvwFLAASAduE5H0FpvtAjKNMWOB\nt4DHAYwx640x440x44EvANXAWg/Wr5RSAPz2q+N46uvX0tBk+Oe/7eDmP225NM57oNmcV8bgPlH0\n7+WdYYlbcucT/QQgzxhz1BhTB7wGLHXdwBno1c6n24DWxij9CrDKZTullPIYi0VYNDaJtffP4PEv\nj6W0ooZvPLedbzy3jV0BNG59vQ+GJW7JnaBPAU66PD/lXNaWbwGrWll+K/BqazuIyDIRyRKRrNLS\nUjdKUkqp1tmsFm65fgAfPziTn9+UzoHCC3zxT1tY9mIWB4uuPg2iL+w+eZ6qukavDkvckkcvxorI\n7UAm8ESL5UlABrCmtf2MMc8aYzKNMZnx8fGeLEkp1U1FhFm5e9oQNvz4Rn40Zzhbj5xh/h8+5YHX\nd3PyrP8aFjYdLsMiMDk1sIK+ABjg8ry/c9llRGQ28DCwxBhT22L1LcA7xpj6zhaqlFKd0SPcxvdn\nDePTH9/IsumpfJBdyBd+9wk/fy+Hkooan9ezKa+MjP5xxEZ5d3IWV+4E/efAMBEZIiJ2HE0wy103\nEJFrgD/jCPmSVo5xG2002yillC/0irbz04Wj+PTHN3JL5gBe2Z7PjCfW89jqA5RX++Yz6IWaenaf\nPM+0od6bZKQ17Qa9MaYB+B6OZpf9wBvGmFwReVREljg3ewLoAbzp7EZ56ReBiAzG8Y1gg4drV0qp\nDkvoGcF/fDGDj350A/NHJ/LMhiNMe/xjnlqfR3VdQ/sH6ILtR8/S2GR8eiEWQAKtr2lmZqbJysry\ndxlKqW7iQFEFv11ziHX7i5mS1odXvjPJa+f65fJcXvs8nz2/mEu4zbMjVorIDmNMZmvr9M5YpVS3\nNjKxJ8/dmcnPFo5ky5Ez7Dhx1mvn2pRXxoQhfTwe8u3RoFdKKeD2SYPoFRXG058c9crxC8svkldS\nyXQfN9uABr1SSgEQZbdx55TBrNtfzKFiz/e335x3BvDNsMQtadArpZTTnZMHExlm5ZkNRzx+7M15\nZfSJtjMyMcbjx26PBr1SSjn1irZz64QBLN99moLzFz12XGMMm/LKmDq0r0+GJW5Jg14ppVx8e3oq\nAM9t9Fxb/aHiSkp9OCxxSxr0SinlIiUukqXjU3jts5Ocq6rzyDE3HnaM4TXVh+PbuNKgV0qpFu65\nIZWL9Y28sPW4R463Oa+M1L7RpMRFeuR4HaVBr5RSLQxLiGH2qAT+uuV4l++WrWtoYvuxs37pbdNM\ng14ppVpx78xUzlfX8/rnJ9vf+Cp25Z+juq7RZ7NJtUaDXimlWnHdoN5MGNyb//v0KPWNTZ0+zuY8\nx7DEk1J9O5CZKw16pZRqw70z0zhdXsPy3ac7fYyNeWWMGxBHbKTvhiVuSYNeKaXaMHNEPCMTY/jz\np0doaur4AJAVNfXsOXneb90qm2nQK6VUG0SEe25I41BxJR8faG2qjavbeuQMTQYNeqWUCmQ3jU0i\nJS6yU8MibM4rIzLMyjUDe3mhMvdp0Cul1FXYrBaWzUgl68Q5Pj/esSGMN+WVMTG1N3abf6NWg14p\npdpxS+YAekfbefoT9z/Vnz5/kaOlVX5vtgENeqWUalek3cpdUwbz8YESDhRVuLXPprwyAL/2n2+m\nQa+UUm745uRBRNmt/HmDe4OdbTpcRt8e4YxI8P2wxC1p0CullBviouzcNmEgy/ec5uTZ6qtu29Rk\n2JxXxrShfRDx/bDELWnQK6WUm749fQgWgec3HbvqdgeLL3Cmqs6v49u40qBXSik3JcU6hzD+PJ8z\nlbVtbrfpcOC0z4MGvVJKdcg9N6RSU9/EC1tPtLnNprwy0uKjSYr1z7DELWnQK6VUBwztF8Pc9ARe\n2HKcqtorhzCubWhk+7EzTB8W74fqWqdBr5RSHXTPzDTKL9bz6mf5V6zbeeI8NfVNAdM+Dxr0SinV\nYdcO7MXEIb15ftMx6houH8J4c14ZVoswMbW3n6q7kga9Ukp1wj0z0ygsr+G93QWXLd+YV8b4AXH0\njPDfsMQtadArpVQnzBzuGML4mQ3/GMK4vLqe7FPnA6rZBjTolVKqU0SEe2emcaS0inX7iwHYerSM\nJgPTA6RbZTMNeqWU6qRFGUkM6B3J0xuOYIxhU14Z0XYr4wfE+bu0y2jQK6VUJ9msFpZNT2VX/nk+\nO3aWTYfLmJjahzBrYEVrYFWjlFJB5quZA+gTbedXK/Zx/Ex1QAxL3JIGvVJKdUFEmJV/mjqYfYWO\n4YsDZdgDVxr0SinVRXdMGky03Uq/mHCG9evh73KuYPN3AUopFexio8L4zZfHYowJiGGJW3LrE72I\nzBeRgyKSJyIPtbL+ARHZJyJ7ReQjERnksm6giKwVkf3ObQZ7rnyllAoMS8Yls3R8ir/LaFW7QS8i\nVuApYAGQDtwmIuktNtsFZBpjxgJvAY+7rHsReMIYMwqYAJR4onCllFLucecT/QQgzxhz1BhTB7wG\nLHXdwBiz3hjTPOXKNqA/gPMXgs0Y86Fzu0qX7ZRSSvmAO0GfApx0eX7Kuawt3wJWOR8PB86LyNsi\nsktEnnB+Q1BKKeUjHu11IyK3A5nAE85FNmA68CBwPZAK3NXKfstEJEtEskpLSz1ZklJKdXvuBH0B\nMMDleX/nssuIyGzgYWCJMaZ5jq1TwG5ns08D8C5wbct9jTHPGmMyjTGZ8fGBM1i/UkqFAneC/nNg\nmIgMERE7cCuw3HUDEbkG+DOOkC9psW+ciDSn9xeAfV0vWymllLvaDXrnJ/HvAWuA/cAbxphcEXlU\nRJY4N3sC6AG8KSK7RWS5c99GHM02H4lINiDA/3nh36GUUqoNYozxdw2XyczMNFlZWf4uQymlgoqI\n7DDGZLa6LtCCXkRKgbanV29fX6DMQ+V4g9bXNVpf12h9XRPI9Q0yxrR6kTPggr6rRCSrrd9qgUDr\n6xqtr2u0vq4J9PraooOaKaVUiNOgV0qpEBeKQf+svwtoh9bXNVpf12h9XRPo9bUq5NrolVJKXS4U\nP9ErpZRyoUGvlFIhLiiD3o2JUMJF5HXn+u2+nOxERAaIyHrnJCu5InJfK9vMFJFy513Eu0Xk576q\nz6WG4yKS7Tz/FXeoicOTztdwr4hcMUaRF2sb4fLa7BaRChG5v8U2Pn0NReQvIlIiIjkuy3qLyIci\nctj5d6829r3Tuc1hEbnTh/U9ISIHnP9/74hIXBv7XvW94MX6fikiBS7/hwvb2PeqP+9erO91l9qO\ni8juNvb1+uvXZcaYoPoDWIEjOEbCtAN7gPQW2/wL8Izz8a3A6z6sLwm41vk4BjjUSn0zgff9/Doe\nB/peZf1CHMNNCzAJ2O7H/+8iHDeD+O01BGbgGJAvx2XZ48BDzscPAY+1sl9v4Kjz717Ox718VN9c\nHPNBADzWWn3uvBe8WN8vgQfd+P+/6s+7t+prsf53wM/99fp19U8wfqJvdyIU5/MXnI/fAmaJ+GYi\nR2NMoTFmp/PxBRzjAwXm/GJXtxR40ThswzE4XZIf6pgFHDHGdOVu6S4zxnwKnG2x2PV99gJwcyu7\nzgM+NMacNcacAz4E5vuiPmPMWuMYqwpcJgTyhzZeP3e48/PeZVerz5kdtwCvevq8vhKMQe/ORCiX\ntnG+0cuBPj6pzoWzyegaYHsrqyeLyB4RWSUio31amIMB1orIDhFZ1sr6jk444y230vYPmL9fwwRj\nTKHzcRGQ0Mo2gfI63s0/JgRqqb33gjd9z9m09Jc2mr4C4fWbDhQbYw63sd6fr59bgjHog4KI9AD+\nDtxvjKlosXonjqaIccD/4hin39emGWOuxTEX8HdFZIYfargqcQyLvQR4s5XVgfAaXmIc3+EDsq+y\niDwMNAAvt7GJv94LTwNpwHigEEfzSCC6jat/mg/4n6VgDHp3JkK5tI2I2IBY4IxPqnOcMwxHyL9s\njHm75XpjTIUxptL5eCUQJiJ9fVWf87wFzr9LgHdwfEV25daEM162ANhpjCluuSIQXkOguLk5y/l3\naxPf+/V1FJG7gJuAbzh/GV3BjfeCVxhjio0xjcaYJhzDl7d2Xn+/fjbgS8DrbW3jr9evI4Ix6Nud\nCMX5vLl3w1eAj9t6k3uasz3veWC/Meb3bWyT2HzNQEQm4Ph/8OUvomgRiWl+jOOiXU6LzZYD33T2\nvpkElLs0U/hKm5+k/P0aOrm+z+4E3mtlmzXAXBHp5WyamOtc5nUiMh/4MY4Jgarb2Mad94K36nO9\n5vPFNs7rzs+7N80GDhhjTrW20p+vX4f4+2pwZ/7g6BFyCMfV+Iedyx7F8YYGiMDxdT8P+AxI9WFt\n03B8hd8L7Hb+WQjcA9zj3OZ7QC6OHgTbgCk+fv1Snefe46yj+TV0rVGAp5yvcTaQ6eMao3EEd6zL\nMr+9hjh+4RQC9Tjaib+F47rPR8BhYB3Q27ltJvCcy753O9+LecA/+bC+PBzt283vw+aeaMnAyqu9\nF3xU39+c7629OMI7qWV9zudX/Lz7oj7n8r82v+dctvX569fVPzoEglJKhbhgbLpRSinVARr0SikV\n4jTolVIqxGnQK6VUiNOgV0qpEKdBr5RSIU6DXimlQtz/B68nWIES+FW6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Orrn0LcHsIbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5b5bbdd0-20fe-458b-e6eb-9051e755f11b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_features_3 (DenseFeatu multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              multiple                  3200      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              multiple                  16512     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              multiple                  129       \n",
            "=================================================================\n",
            "Total params: 19,841\n",
            "Trainable params: 19,841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvgB-xxNsKm3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a397af88-326a-4f2e-af9d-4e1b296f11aa"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     53/Unknown - 0s 9ms/step - loss: 0.5007 - accuracy: 0.8220\n",
            "\n",
            "Test Loss 0.5007370582799304, Test Accuracy 0.8219696879386902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY9iveEosj63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ff045468-76b1-4cb9-d405-c0315b964795"
      },
      "source": [
        "predictions = model.predict(test_data)\n",
        "\n",
        "for prediction, survived in zip(predictions[:10], list(test_data)[0][1][:10]):\n",
        "    print(\"Predicted survival: {:2%}\".format(prediction[0]),\n",
        "          \" | Actual outcome: \", \n",
        "          (\"SURVIVED\" if bool(survived) else \"DIED\"))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted survival: 78.385383%  | Actual outcome:  SURVIVED\n",
            "Predicted survival: 11.011033%  | Actual outcome:  DIED\n",
            "Predicted survival: 53.968948%  | Actual outcome:  SURVIVED\n",
            "Predicted survival: 7.577569%  | Actual outcome:  DIED\n",
            "Predicted survival: 46.212319%  | Actual outcome:  DIED\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}