{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0705_ EfficientNetB7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "11EurjcTH3ZyP1_ncElyo0yb1aJkEhFIV",
      "authorship_tag": "ABX9TyMeBosF29EfI9EwDqyn8E3q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhnJG/AI-Project/blob/master/Colab/0705__EfficientNetB7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-hcyIuBDXlv",
        "colab_type": "text"
      },
      "source": [
        "# Import Lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqCM2kNlE0oN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "48a574d3-ca1e-484e-b4df-f38edc8835f8"
      },
      "source": [
        "!pip install tf-nightly"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/5d/d954f8fbaa7aabcc90b7b437c98b3e927459b720ae4acd1cdaa3a71c8576/tf_nightly-2.4.0.dev20200706-cp36-cp36m-manylinux2010_x86_64.whl (322.9MB)\n",
            "\u001b[K     |████████████████████████████████| 322.9MB 45kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.30.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
            "Collecting tb-nightly<2.4.0a0,>=2.3.0a0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/4a/946de5d29d432f1b09bfeafb2de16fc812d374d3e32aa194d2c899fe87a1/tb_nightly-2.3.0a20200706-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 42.7MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/3c/985ff11fb5b886b7e9acb9781380af7735e0eebf92424ebfb05a1aade546/tf_estimator_nightly-2.4.0.dev2020070601-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 54.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.18.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.2.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tf-nightly) (47.3.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (4.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tf-nightly\n",
            "Successfully installed tb-nightly-2.3.0a20200706 tf-estimator-nightly-2.4.0.dev2020070601 tf-nightly-2.4.0.dev20200706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzFgB9o9i4OY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c7a3aaa-594b-4cf6-a7cc-1d6b25f07faf"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0-dev20200706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN7hTTobDUx0",
        "colab_type": "text"
      },
      "source": [
        "# Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtyWTo9EjOdh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c03dd0ce-232d-4ca2-bc9e-f9d9785b7292"
      },
      "source": [
        "# Data Load\n",
        "# x_data = np.load('/content/drive/My Drive/dacon_voice/data/np_save/preprocessed_melspec_train.npy')\n",
        "x_data = np.load('/content/drive/My Drive/dacon_voice/data/np_save/stacked_melspec_train_96.npy')\n",
        "y_source = pd.read_csv('/content/drive/My Drive/dacon_voice/data/train_answer.csv', index_col=0)\n",
        "y_data = y_source.values\n",
        "\n",
        "# input_shape = (128, 128, 3)\n",
        "input_shape = x_data.shape[1:]\n",
        "\n",
        "print(\"x_train.shape : \", x_data.shape)\n",
        "print(\"input_shape : \", input_shape)\n",
        "print(\"y_data.shape : \", y_data.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.shape :  (100000, 96, 96, 3)\n",
            "input_shape :  (96, 96, 3)\n",
            "y_data.shape :  (100000, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4al7KjlaDdQh",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vChGm3Mm5Pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = '/content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/'\n",
        "model = Sequential()\n",
        "model.add(tf.keras.applications.EfficientNetB7(include_top=True, weights=None, input_shape=input_shape, pooling=None, classes=30))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWjA3Ln_n4g5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "16f710d6-40cd-4952-a0ac-f2f7a4297a9e"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.KLDivergence(), optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnetb7 (Functional)  (None, 30)                64174517  \n",
            "=================================================================\n",
            "Total params: 64,174,517\n",
            "Trainable params: 63,863,790\n",
            "Non-trainable params: 310,727\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wus_mTGzDioo",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg0W7hMku3bD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5eca1f3c-f754-4059-fbc0-30dacf3751f6"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    os.mkdir(model_path)\n",
        "\n",
        "# Validation 점수가 가장 좋은 모델만 저장합니다.\n",
        "model_file_path = model_path + 'Epoch_{epoch:03d}_Val_{val_loss:.3f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=model_file_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "# 10회 간 Validation 점수가 좋아지지 않으면 중지합니다.\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "\n",
        "# 모델을 학습시킵니다.\n",
        "history = model.fit(\n",
        "    x_data, y_data, \n",
        "    epochs=100, batch_size=32, validation_split=0.05, shuffle=False,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 2.4821\n",
            "Epoch 00001: val_loss improved from inf to 2.07352, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_001_Val_2.074.hdf5\n",
            "2969/2969 [==============================] - 873s 294ms/step - loss: 2.4821 - val_loss: 2.0735\n",
            "Epoch 2/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 2.4769\n",
            "Epoch 00002: val_loss did not improve from 2.07352\n",
            "2969/2969 [==============================] - 858s 289ms/step - loss: 2.4769 - val_loss: 2.0815\n",
            "Epoch 3/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 2.4600\n",
            "Epoch 00003: val_loss did not improve from 2.07352\n",
            "2969/2969 [==============================] - 856s 288ms/step - loss: 2.4600 - val_loss: 2.0751\n",
            "Epoch 4/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 2.1104\n",
            "Epoch 00004: val_loss improved from 2.07352 to 2.06981, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_004_Val_2.070.hdf5\n",
            "2969/2969 [==============================] - 863s 291ms/step - loss: 2.1104 - val_loss: 2.0698\n",
            "Epoch 5/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 2.0790\n",
            "Epoch 00005: val_loss did not improve from 2.06981\n",
            "2969/2969 [==============================] - 857s 289ms/step - loss: 2.0790 - val_loss: 2.0724\n",
            "Epoch 6/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 2.0779\n",
            "Epoch 00006: val_loss did not improve from 2.06981\n",
            "2969/2969 [==============================] - 857s 289ms/step - loss: 2.0779 - val_loss: 2.0724\n",
            "Epoch 7/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 2.0446\n",
            "Epoch 00007: val_loss improved from 2.06981 to 2.00456, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_007_Val_2.005.hdf5\n",
            "2969/2969 [==============================] - 864s 291ms/step - loss: 2.0446 - val_loss: 2.0046\n",
            "Epoch 8/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 1.9011\n",
            "Epoch 00008: val_loss improved from 2.00456 to 1.74686, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_008_Val_1.747.hdf5\n",
            "2969/2969 [==============================] - 864s 291ms/step - loss: 1.9011 - val_loss: 1.7469\n",
            "Epoch 9/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 1.6572\n",
            "Epoch 00009: val_loss improved from 1.74686 to 1.53825, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_009_Val_1.538.hdf5\n",
            "2969/2969 [==============================] - 863s 291ms/step - loss: 1.6572 - val_loss: 1.5383\n",
            "Epoch 10/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 1.5016\n",
            "Epoch 00010: val_loss improved from 1.53825 to 1.43235, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_010_Val_1.432.hdf5\n",
            "2969/2969 [==============================] - 863s 291ms/step - loss: 1.5016 - val_loss: 1.4324\n",
            "Epoch 11/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 1.3351\n",
            "Epoch 00011: val_loss improved from 1.43235 to 1.25882, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_011_Val_1.259.hdf5\n",
            "2969/2969 [==============================] - 863s 291ms/step - loss: 1.3351 - val_loss: 1.2588\n",
            "Epoch 12/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 1.2041\n",
            "Epoch 00012: val_loss improved from 1.25882 to 1.20082, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_012_Val_1.201.hdf5\n",
            "2969/2969 [==============================] - 863s 291ms/step - loss: 1.2041 - val_loss: 1.2008\n",
            "Epoch 13/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 1.0936\n",
            "Epoch 00013: val_loss improved from 1.20082 to 1.10699, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_013_Val_1.107.hdf5\n",
            "2969/2969 [==============================] - 863s 291ms/step - loss: 1.0936 - val_loss: 1.1070\n",
            "Epoch 14/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.9997\n",
            "Epoch 00014: val_loss improved from 1.10699 to 1.03913, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_014_Val_1.039.hdf5\n",
            "2969/2969 [==============================] - 863s 291ms/step - loss: 0.9997 - val_loss: 1.0391\n",
            "Epoch 15/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.9170\n",
            "Epoch 00015: val_loss improved from 1.03913 to 0.98391, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_015_Val_0.984.hdf5\n",
            "2969/2969 [==============================] - 863s 291ms/step - loss: 0.9170 - val_loss: 0.9839\n",
            "Epoch 16/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.8434\n",
            "Epoch 00016: val_loss improved from 0.98391 to 0.97321, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_016_Val_0.973.hdf5\n",
            "2969/2969 [==============================] - 863s 291ms/step - loss: 0.8434 - val_loss: 0.9732\n",
            "Epoch 17/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.7784\n",
            "Epoch 00017: val_loss improved from 0.97321 to 0.96004, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_017_Val_0.960.hdf5\n",
            "2969/2969 [==============================] - 864s 291ms/step - loss: 0.7784 - val_loss: 0.9600\n",
            "Epoch 18/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.7210\n",
            "Epoch 00018: val_loss improved from 0.96004 to 0.94617, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_018_Val_0.946.hdf5\n",
            "2969/2969 [==============================] - 864s 291ms/step - loss: 0.7210 - val_loss: 0.9462\n",
            "Epoch 19/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.6688\n",
            "Epoch 00019: val_loss improved from 0.94617 to 0.94530, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_019_Val_0.945.hdf5\n",
            "2969/2969 [==============================] - 864s 291ms/step - loss: 0.6688 - val_loss: 0.9453\n",
            "Epoch 20/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.6240\n",
            "Epoch 00020: val_loss improved from 0.94530 to 0.92781, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_020_Val_0.928.hdf5\n",
            "2969/2969 [==============================] - 864s 291ms/step - loss: 0.6240 - val_loss: 0.9278\n",
            "Epoch 21/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.5822\n",
            "Epoch 00021: val_loss improved from 0.92781 to 0.91134, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_021_Val_0.911.hdf5\n",
            "2969/2969 [==============================] - 864s 291ms/step - loss: 0.5822 - val_loss: 0.9113\n",
            "Epoch 22/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.5451\n",
            "Epoch 00022: val_loss did not improve from 0.91134\n",
            "2969/2969 [==============================] - 857s 289ms/step - loss: 0.5451 - val_loss: 0.9192\n",
            "Epoch 23/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.5132\n",
            "Epoch 00023: val_loss improved from 0.91134 to 0.88699, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_023_Val_0.887.hdf5\n",
            "2969/2969 [==============================] - 864s 291ms/step - loss: 0.5132 - val_loss: 0.8870\n",
            "Epoch 24/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.4829\n",
            "Epoch 00024: val_loss did not improve from 0.88699\n",
            "2969/2969 [==============================] - 856s 288ms/step - loss: 0.4829 - val_loss: 0.9146\n",
            "Epoch 25/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.4563\n",
            "Epoch 00025: val_loss did not improve from 0.88699\n",
            "2969/2969 [==============================] - 857s 289ms/step - loss: 0.4563 - val_loss: 0.9164\n",
            "Epoch 26/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.4342\n",
            "Epoch 00026: val_loss did not improve from 0.88699\n",
            "2969/2969 [==============================] - 857s 289ms/step - loss: 0.4342 - val_loss: 0.9237\n",
            "Epoch 27/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.4106\n",
            "Epoch 00027: val_loss did not improve from 0.88699\n",
            "2969/2969 [==============================] - 856s 288ms/step - loss: 0.4106 - val_loss: 0.9028\n",
            "Epoch 28/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.3916\n",
            "Epoch 00028: val_loss improved from 0.88699 to 0.87829, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_028_Val_0.878.hdf5\n",
            "2969/2969 [==============================] - 864s 291ms/step - loss: 0.3916 - val_loss: 0.8783\n",
            "Epoch 29/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.3733\n",
            "Epoch 00029: val_loss did not improve from 0.87829\n",
            "2969/2969 [==============================] - 858s 289ms/step - loss: 0.3733 - val_loss: 0.8970\n",
            "Epoch 30/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.3569\n",
            "Epoch 00030: val_loss improved from 0.87829 to 0.86064, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_030_Val_0.861.hdf5\n",
            "2969/2969 [==============================] - 861s 290ms/step - loss: 0.3569 - val_loss: 0.8606\n",
            "Epoch 31/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.3413\n",
            "Epoch 00031: val_loss did not improve from 0.86064\n",
            "2969/2969 [==============================] - 857s 289ms/step - loss: 0.3413 - val_loss: 0.8730\n",
            "Epoch 32/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.3279\n",
            "Epoch 00032: val_loss did not improve from 0.86064\n",
            "2969/2969 [==============================] - 856s 288ms/step - loss: 0.3279 - val_loss: 0.9066\n",
            "Epoch 33/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.3137\n",
            "Epoch 00033: val_loss did not improve from 0.86064\n",
            "2969/2969 [==============================] - 857s 289ms/step - loss: 0.3137 - val_loss: 0.8814\n",
            "Epoch 34/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.3022\n",
            "Epoch 00034: val_loss did not improve from 0.86064\n",
            "2969/2969 [==============================] - 857s 289ms/step - loss: 0.3022 - val_loss: 0.9157\n",
            "Epoch 35/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2932\n",
            "Epoch 00035: val_loss did not improve from 0.86064\n",
            "2969/2969 [==============================] - 857s 289ms/step - loss: 0.2932 - val_loss: 0.9061\n",
            "Epoch 36/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2818\n",
            "Epoch 00036: val_loss did not improve from 0.86064\n",
            "2969/2969 [==============================] - 857s 289ms/step - loss: 0.2818 - val_loss: 0.8790\n",
            "Epoch 37/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2741\n",
            "Epoch 00037: val_loss did not improve from 0.86064\n",
            "2969/2969 [==============================] - 857s 289ms/step - loss: 0.2741 - val_loss: 0.9182\n",
            "Epoch 38/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2654\n",
            "Epoch 00038: val_loss did not improve from 0.86064\n",
            "2969/2969 [==============================] - 857s 289ms/step - loss: 0.2654 - val_loss: 0.8929\n",
            "Epoch 39/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2577\n",
            "Epoch 00039: val_loss did not improve from 0.86064\n",
            "2969/2969 [==============================] - 858s 289ms/step - loss: 0.2577 - val_loss: 0.8844\n",
            "Epoch 40/100\n",
            " 888/2969 [=======>......................] - ETA: 9:53 - loss: 0.2539"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e8GI_vZJpc8",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcsGGTmGA743",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "459ae6c4-9fa7-44aa-f691-e9760888f067"
      },
      "source": [
        "x_test = np.load('/content/drive/My Drive/dacon_voice/data/np_save/stacked_melspec_test_96.npy')\n",
        "print(x_test.shape)\n",
        "# x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2], 1)\n",
        "\n",
        "# 가장 좋은 모델의 weight를 불러옵니다.\n",
        "weigth_file = glob(model_path + '*.hdf5')[-1]\n",
        "\n",
        "# weight_file = '/content/drive/My Drive/dacon_voice/model/20200705_ResNet152V2/Epoch_005_Val_0.911.hdf5'\n",
        "print(weight_file)\n",
        "model.load_weights(weight_file)\n",
        "\n",
        "# 예측 수행\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# 현재 시간 구하기\n",
        "import time \n",
        "now = time.localtime()\n",
        "now = \"%04d%02d%02d_%02d%02d%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour+9, now.tm_min, now.tm_sec)\n",
        "print(now)\n",
        "\n",
        "# 예측 결과로 제출 파일을 생성합니다.\n",
        "submission = pd.read_csv('/content/drive/My Drive/dacon_voice/data/submission.csv', index_col=0)\n",
        "submission.loc[:, :] = y_pred\n",
        "submission.to_csv('/content/drive/My Drive/dacon_voice/result/'+ now +'_submission.csv')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 96, 96, 3)\n",
            "/content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_030_Val_0.861.hdf5\n",
            "20200706_262806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_eWFiskJs6M",
        "colab_type": "text"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4K2iP59DxRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56489653-6ad8-48a3-c172-848643bbaf6a"
      },
      "source": [
        "from keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from glob import glob\n",
        "\n",
        "# 가장 좋은 모델의 weight를 불러옵니다.\n",
        "# weigth_file = glob('model/*.hdf5')[-1]\n",
        "weight_file = glob(model_path + '*.hdf5')[-1]\n",
        "# weight_file = '/content/drive/My Drive/dacon_voice/model/Epoch_001_Val_2.083.hdf5'\n",
        "print(weight_file)\n",
        "\n",
        "# load h5\n",
        "model = tf.keras.models.load_model(weight_file)\n",
        "\n",
        "# model compile\n",
        "# model.compile(loss=tf.keras.losses.KLDivergence(), optimizer='adam')\n",
        "\n",
        "# Validation 점수가 가장 좋은 모델만 저장합니다.\n",
        "model_file_path = model_path + 'Epoch_{epoch:03d}_Val_{val_loss:.3f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=model_file_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "# 10회 간 Validation 점수가 좋아지지 않으면 중지합니다.\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "\n",
        "# 모델을 학습시킵니다.\n",
        "history = model.fit(\n",
        "    x_data, y_data, \n",
        "    epochs=100, batch_size=32, validation_split=0.05, shuffle=False,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_030_Val_0.861.hdf5\n",
            "Epoch 1/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.3430\n",
            "Epoch 00001: val_loss improved from inf to 0.91412, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_001_Val_0.914.hdf5\n",
            "2969/2969 [==============================] - 864s 291ms/step - loss: 0.3430 - val_loss: 0.9141\n",
            "Epoch 2/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.3275\n",
            "Epoch 00002: val_loss improved from 0.91412 to 0.86528, saving model to /content/drive/My Drive/dacon_voice/model/20200706_EfficientNetB7/Epoch_002_Val_0.865.hdf5\n",
            "2969/2969 [==============================] - 855s 288ms/step - loss: 0.3275 - val_loss: 0.8653\n",
            "Epoch 3/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.3159\n",
            "Epoch 00003: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 847s 285ms/step - loss: 0.3159 - val_loss: 0.8844\n",
            "Epoch 4/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.3023\n",
            "Epoch 00004: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 844s 284ms/step - loss: 0.3023 - val_loss: 0.9166\n",
            "Epoch 5/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2909\n",
            "Epoch 00005: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 844s 284ms/step - loss: 0.2909 - val_loss: 0.9076\n",
            "Epoch 6/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2823\n",
            "Epoch 00006: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 844s 284ms/step - loss: 0.2823 - val_loss: 0.8888\n",
            "Epoch 7/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2725\n",
            "Epoch 00007: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 845s 284ms/step - loss: 0.2725 - val_loss: 0.8868\n",
            "Epoch 8/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2646\n",
            "Epoch 00008: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 843s 284ms/step - loss: 0.2646 - val_loss: 0.8952\n",
            "Epoch 9/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2573\n",
            "Epoch 00009: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 843s 284ms/step - loss: 0.2573 - val_loss: 0.9138\n",
            "Epoch 10/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2492\n",
            "Epoch 00010: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 842s 284ms/step - loss: 0.2492 - val_loss: 0.8850\n",
            "Epoch 11/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2419\n",
            "Epoch 00011: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 842s 284ms/step - loss: 0.2419 - val_loss: 0.8915\n",
            "Epoch 12/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2354\n",
            "Epoch 00012: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 842s 284ms/step - loss: 0.2354 - val_loss: 0.9092\n",
            "Epoch 13/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2281\n",
            "Epoch 00013: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 844s 284ms/step - loss: 0.2281 - val_loss: 0.8967\n",
            "Epoch 14/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2233\n",
            "Epoch 00014: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 844s 284ms/step - loss: 0.2233 - val_loss: 0.9055\n",
            "Epoch 15/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2177\n",
            "Epoch 00015: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 843s 284ms/step - loss: 0.2177 - val_loss: 0.8993\n",
            "Epoch 16/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2129\n",
            "Epoch 00016: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 844s 284ms/step - loss: 0.2129 - val_loss: 0.9034\n",
            "Epoch 17/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2058\n",
            "Epoch 00017: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 843s 284ms/step - loss: 0.2058 - val_loss: 0.9069\n",
            "Epoch 18/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.2022\n",
            "Epoch 00018: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 842s 284ms/step - loss: 0.2022 - val_loss: 0.9247\n",
            "Epoch 19/100\n",
            "2969/2969 [==============================] - ETA: 0s - loss: 0.1974\n",
            "Epoch 00019: val_loss did not improve from 0.86528\n",
            "2969/2969 [==============================] - 842s 284ms/step - loss: 0.1974 - val_loss: 0.9190\n",
            "Epoch 20/100\n",
            " 273/2969 [=>............................] - ETA: 12:32 - loss: 0.1973"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1289eb7465bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \"\"\"\n\u001b[1;32m   1063\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY-LNklCM4Yk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}